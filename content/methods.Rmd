---
title: "Open Source Software 2020 Summer Project"
output: html_document
---

```{css, echo=FALSE}
/* this chunnk of code centers all of the headings */
h1, h2, h3 {
  text-align: center;
}
```

### Data and Methods

In order to provide our stakeholder, the [Army Research Institute](https://ari.altess.army.mil/), with pertinant insight regarding the fesability of predicting behavioral performance using existing data sources we must first identify existing authoratative behavioral performance items from academic, industry, government and military sources.  In essence, the collection of this corpus of documents will serve as the basis from which a consensus regarding themes and topics relating to behavioral performance will be extracted.  Thus our first goal was:

>To identify documents from academic, industry, government, and military >sources which contain assessment scale items measuring various manifestations >and/or notions of performance.

```{r packages, message = FALSE, results = FALSE, warning = FALSE, echo=FALSE}
rm(list = ls())
# load packages 
for (pkg in c("tidyverse", "igraph", "visNetwork", "data.table", "R.utils", "DT", "RPostgreSQL", "cowplot", "maditr", "stringr", "stringi", "gridExtra","readxl")) {library(pkg, character.only = TRUE)}

documentTablePath <- system('git ls-files --full-name DocumentSheetOnly.xls')

documentTable <- read_excel(documentTablePath)

datatable(documentTable)
```

Having achived this, we now needed to extract the individual assesment items (i.e. "questions") from each of these documents so that the terms *explicitly* used in the assesment items (and, presumably, the latent variables they correspond to) could be subjected to analysis.  Furethermore, in order to maximally facilitate secondary analysis, additional characteristics were manually ascribed to the assesment items, based on a number of criteria.  Thus, our second goal was: 

>For each of the documents identified in the previous step: extract each >assessment item present in the document and characterize it based on (1) >provenance; (2) general theme, content, and target; (3) Koopmans et al. >framework features and characteristics; and (4) quality/quantity of assessment >scale items.

With the assesment items extracted, we then needed to determine what common topics and themes they shared.  Thus our third goal was:

>Perform a text analysis on the extracted items, and attempt to characterize >the topic groups and their relations

With the litterature's themes now avaiable to us, we would next be able to map these back on to the data collection tools used by the military.  Thus our fourth and final goal was:

>Time permitting, compare these groups to assessment items and tools used by >the military in order to assess overlap and determine suitability of those >items for potential application to military personnel. 

<center>

##### [Visualizations go about here.] 

</center>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam in varius purus. Nullam ut sodales ante. Fusee justo nisi, suscipit a lacus et, posuere sagittis ex. Nulla convallis ante elit, at consequat ipsum ultricies ut. Aliquam erat volutpat. nderline. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam in variu convallis ante elit, at consequat ipsum ultricies ut.

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam in varius purus. Nullam ut sodales ante. Fusee justo nisi, suscipit a lacus et, posuere sagittis ex. Nulla convallis ante elit, at consequat ipsum ultricies ut. Aliquam erat volutpat. nderline. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam in variu convallis ante elit, at consequat ipsum ultricies ut.