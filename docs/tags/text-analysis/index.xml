<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>text analysis on UVA Biocomplexity Institute</title>
    <link>/tags/text-analysis/</link>
    <description>Recent content in text analysis on UVA Biocomplexity Institute</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/tags/text-analysis/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring Job Performance Scales</title>
      <link>/findings/performance_tidy_text/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/findings/performance_tidy_text/</guid>
      <description>/* this chunk of code centers all of the headings */ h1, h2, h3 { text-align: center; }  Approach Once we compiled potential scale items, we extracted the scales from the collection of papers on job performance. The following table displays the relevant scale items we have collected. Before we explored two different topic modeling approaches, we wanted to get a sense of the the content and sources of the scale items.</description>
    </item>
    
    <item>
      <title>Job Performance Scales: LDA Topic Modeling</title>
      <link>/findings/performance_lda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/findings/performance_lda/</guid>
      <description>/* this chunk of code centers all of the headings */ h1, h2, h3 { text-align: center; }  Approach Once we gathered a corpus of scales from a variety of sources, we wanted to be able to analyze these scales cohesively. Latent Dirichlet Allocation (LDA) is a probabalistic topic modeling process which considers each document as a distribution of topics and each topic as a distribution of words.</description>
    </item>
    
    <item>
      <title>Biterm Modeling of Performance Scales</title>
      <link>/findings/biterm_markdown/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/findings/biterm_markdown/</guid>
      <description>/* this chunk of code centers all of the headings */ h1, h2, h3 { text-align: center; }  About BTM Biterm Topic Modeling (BTM) is a method of detecting the topics occurring in short texts. In other approaches to topic modeling, each document is analyzed for topic occurences within that document. The challenge with applying traditional topic modeling techniques to short documents is that there is not enough data to work with.</description>
    </item>
    
  </channel>
</rss>