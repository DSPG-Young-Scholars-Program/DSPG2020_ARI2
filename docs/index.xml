<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>UVA Biocomplexity Institute</title>
    <link>/</link>
    <description>Recent content on UVA Biocomplexity Institute</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ARI Individual Performance 2020 Summer Project</title>
      <link>/methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/methods/</guid>
      <description>/* this chunnk of code centers all of the headings */ h1, h2, h3 { text-align: center; }  Data and Methods In order to provide our stakeholder, the Army Research Institute, with pertinant insight regarding the fesability of predicting behavioral performance using existing data sources we must first identify existing authoratative behavioral performance items from academic, industry, government and military sources. In essence, the collection of this corpus of documents will serve as the basis from which a consensus regarding themes and topics relating to behavioral performance will be extracted.</description>
    </item>
    
    <item>
      <title>ARI Individual Performance 2020 Summer Project</title>
      <link>/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/overview/</guid>
      <description>/* this chunnk of code centers all of the headings */ h1, h2, h3 { text-align: center; }  Project Overview According to the Data Manpower Data Center (DMDC) the United States Army approximately 475 thousand active duty, and approximately 190 thousand reserve, service members. As part of its standard personnel management practices it collects a number of measures and/or surveys from and about these service members. Given the scope, depth, duration of this data source, the U.</description>
    </item>
    
    <item>
      <title>ARI Individual Performance 2020 Summer Project</title>
      <link>/team/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/team/</guid>
      <description>/* this chunnk of code centers all of the headings */ h1, h2, h3 { text-align: center; }  UVA Data Science for the Public Good The Data Science for the Public Good (DSPG) Young Scholars program is a summer immersive program held at the Biocomplexity Instituteâ€™s Social and Decision Analytics division (SDAD). In its seventh year, the program engages students from across the country to work together on projects that address state, federal, and local government challenges around critical social issues relevant in the world today.</description>
    </item>
    
    <item>
      <title>Job Performance: LDA Topic Modeling</title>
      <link>/findings/performance_lda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/findings/performance_lda/</guid>
      <description>Data Setup This is the part where I am importing the data. I choose to combine the STEM and the ITEM so both parts of the scale were included. I also collapse the scales by citation, so each document is a full scale rather than a part of a scale.
job_perf &amp;lt;- read_csv(&amp;quot;/project/class/bii_sdad_dspg/uva/dod_ari2/ari2_07_21.csv&amp;quot;) ## Warning: Missing column names filled in: &amp;#39;X19&amp;#39; [19], &amp;#39;X20&amp;#39; [20], &amp;#39;X21&amp;#39; [21] ## Parsed with column specification: ## cols( ## .</description>
    </item>
    
    <item>
      <title>Job Performance: Tidy Text</title>
      <link>/findings/performance_tidy_text/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/findings/performance_tidy_text/</guid>
      <description>Tidy Text Analysis for Job Performance Scales library(dplyr) library(tidyverse) library(tidytext) library(stm) library(quanteda) library(ggplot2) library(readr) library(stringr) library(reshape2) library(wordcloud) job_perf &amp;lt;- read_csv(&amp;quot;/project/class/bii_sdad_dspg/uva/dod_ari2/ari2_07_21.csv&amp;quot;) cols &amp;lt;- c(&amp;#39;STEM&amp;#39;, &amp;#39;ITEM&amp;#39;) job_perf$scale &amp;lt;- apply( job_perf[ , cols ], 1 , paste, collapse = &amp;quot; &amp;quot;) job_perf$scale &amp;lt;- gsub(&amp;quot;NA&amp;quot;,&amp;#39; &amp;#39;, job_perf$scale)  Word Frequency in Scales #Tidying the data tidy_perf &amp;lt;- tibble(source = job_perf$SOURCE_DOMAIN, text = job_perf$scale) data(stop_words) tidy_perf &amp;lt;- tidy_perf %&amp;gt;% unnest_tokens(word, text) %&amp;gt;% anti_join(stop_words) %&amp;gt;% count(source, word, sort = TRUE) %&amp;gt;% filter(word !</description>
    </item>
    
  </channel>
</rss>